#<center>cachetable</center>

#1.cachefile(CACHEFILE)

```cpp
typedef struct cachefile *CACHEFILE;

///////////////////////////////////////////////////////////////////////////////
//
// Maps to a file on disk.
//
struct cachefile {
    // these next two fields are protected by cachetable's list lock
    // they are managed whenever we add or remove a pair from
    // the cachetable. As of Riddler, this linked list is only used to
    // make cachetable_flush_cachefile more efficient
    PAIR cf_head; // doubly linked list that is NOT circular
    uint32_t num_pairs; // count on number of pairs in the cachetable belong to this cachefile

    bool for_checkpoint; //True if part of the in-progress checkpoint

    // If set and the cachefile closes, the file will be removed.
    // Clients must not operate on the cachefile after setting this,
    // nor attempt to open any cachefile with the same fname (dname)
    // until this cachefile has been fully closed and unlinked.
    bool unlink_on_close;
    // If set then fclose will not be logged in recovery log.
    bool skip_log_recover_on_close;
    int fd;       /* Bug: If a file is opened read-only, then it is stuck in read-only.  If it is opened read-write, then subsequent writers can write to it too. */
    CACHETABLE cachetable;
    struct fileid fileid;
    // the filenum is used as an identifer of the cachefile
    // for logging and recovery
    FILENUM filenum;
    // number used to generate hashes for blocks in the cachefile
    // used in toku_cachetable_hash
    // this used to be the filenum.fileid, but now it is separate
    uint32_t hash_id;
    char *fname_in_env; /* Used for logging */

    void *userdata;
    void (*log_fassociate_during_checkpoint)(CACHEFILE cf, void *userdata); // When starting a checkpoint we must log all open files.
    void (*close_userdata)(CACHEFILE cf, int fd, void *userdata, bool lsnvalid, LSN); // when closing the last reference to a cachefile, first call this function.
    void (*free_userdata)(CACHEFILE cf, void *userdata); // when closing the last reference to a cachefile, first call this function.
    void (*begin_checkpoint_userdata)(LSN lsn_of_checkpoint, void *userdata); // before checkpointing cachefiles call this function.
    void (*checkpoint_userdata)(CACHEFILE cf, int fd, void *userdata); // when checkpointing a cachefile, call this function.
    void (*end_checkpoint_userdata)(CACHEFILE cf, int fd, void *userdata); // after checkpointing cachefiles call this function.
    void (*note_pin_by_checkpoint)(CACHEFILE cf, void *userdata); // add a reference to the userdata to prevent it from being removed from memory
    void (*note_unpin_by_checkpoint)(CACHEFILE cf, void *userdata); // add a reference to the userdata to prevent it from being removed from memory
    BACKGROUND_JOB_MANAGER bjm;
};
```

#2.class cachefile_list

```cpp
///////////////////////////////////////////////////////////////////////////////
//
// Wrapper for the head of our cachefile list.
//
class cachefile_list {
public:
    void init();
    void destroy();
    void read_lock();
    void read_unlock();
    void write_lock();
    void write_unlock();
    int cachefile_of_iname_in_env(const char *iname_in_env, CACHEFILE *cf);
    int cachefile_of_filenum(FILENUM filenum, CACHEFILE *cf);
    void add_cf_unlocked(CACHEFILE newcf);
    void add_stale_cf(CACHEFILE newcf);
    void remove_cf(CACHEFILE cf);
    void remove_stale_cf_unlocked(CACHEFILE cf);
    FILENUM reserve_filenum();
    uint32_t get_new_hash_id_unlocked();
    CACHEFILE find_cachefile_unlocked(struct fileid* fileid);
    CACHEFILE find_stale_cachefile_unlocked(struct fileid* fileid);
    void verify_unused_filenum(FILENUM filenum);
    bool evict_some_stale_pair(evictor* ev);
    void free_stale_data(evictor* ev);
    // access to these fields are protected by the lock
    FILENUM m_next_filenum_to_use;
    uint32_t m_next_hash_id_to_use;
    toku_pthread_rwlock_t m_lock; // this field is publoc so we are still POD
    toku::omt<CACHEFILE> m_active_filenum;
    toku::omt<CACHEFILE> m_active_fileid;
    toku::omt<CACHEFILE> m_stale_fileid;
private:
    CACHEFILE find_cachefile_in_list_unlocked(CACHEFILE start, struct fileid* fileid);
};
```

#3.checkpointer(CHECKPOINTER)

```cpp
typedef class checkpointer *CHECKPOINTER;

///////////////////////////////////////////////////////////////////////////////
//
//  The checkpointer handles starting and finishing checkpoints of the
//  cachetable's data.
//
class checkpointer {
public:
    int init(pair_list *_pl, TOKULOGGER _logger, evictor *_ev, cachefile_list *files);
    void destroy();
    void set_checkpoint_period(uint32_t new_period);
    uint32_t get_checkpoint_period();
    int shutdown();
    bool has_been_shutdown();
    void begin_checkpoint();
    void add_background_job();
    void remove_background_job();
    void end_checkpoint(void (*testcallback_f)(void*),  void* testextra);
    void begin_backup();
    void end_backup();
    TOKULOGGER get_logger();
    // used during begin_checkpoint
    void increment_num_txns();
private:
    uint32_t m_checkpoint_num_txns;   // how many transactions are in the checkpoint
    TOKULOGGER m_logger;
    LSN m_lsn_of_checkpoint_in_progress;
    uint32_t m_checkpoint_num_files; // how many cachefiles are in the checkpoint
    struct minicron m_checkpointer_cron; // the periodic checkpointing thread
    cachefile_list *m_cf_list;
    pair_list *m_list;
    evictor *m_ev;
    bool m_checkpointer_cron_init;
    bool m_checkpointer_init;

    // variable used by the checkpoint thread to know
    // when all work induced by cloning on client threads is done
    BACKGROUND_JOB_MANAGER m_checkpoint_clones_bjm;
    // private methods for begin_checkpoint
    void update_cachefiles();
    void log_begin_checkpoint();
    void turn_on_pending_bits();
    // private methods for end_checkpoint
    void fill_checkpoint_cfs(CACHEFILE* checkpoint_cfs);
    void checkpoint_pending_pairs();
    void checkpoint_userdata(CACHEFILE* checkpoint_cfs);
    void log_end_checkpoint();
    void end_checkpoint_userdata(CACHEFILE* checkpoint_cfs);
    void remove_cachefiles(CACHEFILE* checkpoint_cfs);

    // Unit test struct needs access to private members.
    friend struct checkpointer_test;
};
```

#4. ctpair(PAIR)

```cpp
typedef struct ctpair *PAIR;

///////////////////////////////////////////////////////////////////////////////
//
//  The pair represents the data stored in the cachetable.
//
struct ctpair {
    // these fields are essentially constants. They do not change.
    CACHEFILE cachefile;
    CACHEKEY key;
    uint32_t fullhash;
    CACHETABLE_FLUSH_CALLBACK flush_callback;
    CACHETABLE_PARTIAL_EVICTION_EST_CALLBACK pe_est_callback;
    CACHETABLE_PARTIAL_EVICTION_CALLBACK pe_callback;
    CACHETABLE_CLEANER_CALLBACK cleaner_callback;
    CACHETABLE_CLONE_CALLBACK clone_callback;
    CACHETABLE_CHECKPOINT_COMPLETE_CALLBACK checkpoint_complete_callback;
    void *write_extraargs;

    // access to these fields are protected by disk_nb_mutex
    void* cloned_value_data; // cloned copy of value_data used for checkpointing
    long cloned_value_size; // size of cloned_value_data, used for accounting of size_current
    void* disk_data; // data used to fetch/flush value_data to and from disk.

    // access to these fields are protected by value_rwlock
    void* value_data; // data used by client threads, FTNODEs and ROLLBACK_LOG_NODEs
    PAIR_ATTR attr;
    enum cachetable_dirty dirty;

    // protected by PAIR->mutex
    uint32_t count;        // clock count
    uint32_t refcount; // if > 0, then this PAIR is referenced by
                       // callers to the cachetable, and therefore cannot
                       // be evicted
    uint32_t num_waiting_on_refs; // number of threads waiting on refcount to go to zero
    toku_cond_t refcount_wait; // cond used to wait for refcount to go to zero

    // locks
    toku::frwlock value_rwlock;
    struct nb_mutex disk_nb_mutex; // single writer, protects disk_data, is used for writing cloned nodes for checkpoint
    toku_mutex_t* mutex; // gotten from the pair list

    // Access to checkpoint_pending is protected by two mechanisms,
    // the value_rwlock and the pair_list's pending locks (expensive and cheap).
    // checkpoint_pending may be true of false.
    // Here are the rules for reading/modifying this bit.
    //  - To transition this field from false to true during begin_checkpoint,
    //   we must be holding both of the pair_list's pending locks.
    //  - To transition this field from true to false during end_checkpoint,
    //   we must be holding the value_rwlock.
    //  - For a non-checkpoint thread to read the value, we must hold both the
    //   value_rwlock and one of the pair_list's pending locks
    //  - For the checkpoint thread to read the value, we must
    //   hold the value_rwlock
    //
    bool checkpoint_pending; // If this is on, then we have got to resolve checkpointing modifying it.

    // these are variables that are only used to transfer information to background threads
    // we cache them here to avoid a malloc. In the future, we should investigate if this
    // is necessary, as having these fields here is not technically necessary
    long size_evicting_estimate;
    evictor* ev;
    pair_list* list;

    // A PAIR is stored in a pair_list (which happens to be PAIR->list).
    // These variables are protected by the list lock in the pair_list
    //
    // clock_next,clock_prev represent a circular doubly-linked list.
    PAIR clock_next,clock_prev; // In clock.
    PAIR hash_chain;

    // pending_next,pending_next represent a non-circular doubly-linked list.
    PAIR pending_next;
    PAIR pending_prev;

    // cf_next, cf_prev represent a non-circular doubly-linked list.
    // entries in linked list for PAIRs in a cachefile, these are protected
    // by the list lock of the PAIR's pair_list. They are used to make
    // cachetable_flush_cachefile cheaper so that we don't need
    // to search the entire cachetable to find a particular cachefile's
    // PAIRs
    PAIR cf_next;
    PAIR cf_prev;
};    
```

#5. cachetable(CACHETABLE)

```cpp
typedef struct cachetable *CACHETABLE;

///////////////////////////////////////////////////////////////////////////////
//
// The cachetable is as close to an ENV as we get.
//
struct cachetable {
    pair_list list;
    cleaner cl;
    evictor ev;
    checkpointer cp;
    cachefile_list cf_list;

    KIBBUTZ client_kibbutz; // pool of worker threads and jobs to do asynchronously for the client.
    KIBBUTZ ct_kibbutz; // pool of worker threads and jobs to do asynchronously for the cachetable
    KIBBUTZ checkpointing_kibbutz; // small pool for checkpointing cloned pairs
    bool in_backup; // we are in back up or NOT, default is false

    char *env_dir;
};
```

#6. pair_attr_s(PAIR_ATTR)

```cpp
// This struct hold information about values stored in the cachetable.
// As one can tell from the names, we are probably violating an
// abstraction layer by placing names.
//
// The purpose of having this struct is to have a way for the
// cachetable to accumulate the some totals we are interested in.
// Breaking this abstraction layer by having these names was the
// easiest way.
//
typedef struct pair_attr_s {
    long size; // size PAIR's value takes in memory
    long nonleaf_size; // size if PAIR is a nonleaf node, 0 otherwise, used only for engine status
    long leaf_size; // size if PAIR is a leaf node, 0 otherwise, used only for engine status
    long rollback_size; // size of PAIR is a rollback node, 0 otherwise, used only for engine status
    long cache_pressure_size; // amount PAIR contributes to cache pressure, is sum of buffer sizes and workdone counts
    bool is_valid;
} PAIR_ATTR;
```