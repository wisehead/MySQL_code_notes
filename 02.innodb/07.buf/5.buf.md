## buf pool概念基础
## 1.TBD

## 2.缓冲区缓冲的页类型

索引页，数据页，undo页，插入缓存(insert buffer)，自适应哈希(adaptive hash index)、锁信息（lock info）

锁信息：
每个事务锁的信息是在trx_struct对象的lock_heap变量中进行分配的。而由于mem_heap_t的特性，当申请的空间大于8KB时候，就会从缓冲池分配。

ADI，lock info不进入LRU

## 3.LRU算法

buffer_pool->LRU_old指向LRU链表长度的3/8处。
疑问：到底是3/8 new，还是 3/8 old。

## 4.LRU链表维护

关键数据结构：
--buf_pool->freeed_page_clock:每次page从bp中被换出时候，该值加1. block->freed_page_clock表示上次将page移动到LRU首部的时候，buf_pool->freed_page_clock的值。
--buf_pool->ulint_clock每个页放入bp的时间，从而知道page在热端的位置，是否为热端最活跃的page。

当页已经被读到buffer pool，那么当再次被读取时，需要维护该页在LRU链表中的位置。这个操作由 buf_block_make_young完成。
然而，并不是每次读取到页都需要放入到LRU链表的首部。若页已经处于一个比较活跃的位置，也就是LRU链表的前端部分，则不需要进行移动。

if (buf_pool->freed_page_clock >= block->freed_page_clock + 1 + (buf_pool->cur_size / 1024))
{
	    buf_LRU_make_block_young(block);
}


每次往bp增加一个page，buf_pool->ulint_clock都会+1. 同时block->LRU_position会记录当前的ulint_clock的值。
LRU_position值越大说明page在bp中的活跃度越高，被替换出去的概率越小。

在热端，LRU_position从头部到LRU_old的块是依次递减的。而在冷端的块，LRU_position的值都相同。（疑问：为啥都一样？？？？）

当page被flush到磁盘后，会将page移到LRU尾端。表示可以从LRU链表中被替换，函数buf_LRU_make_block_old()实现。

## 5.page read

最底层的函数是
buf_read_page_low
--buf_page_init_for_read//从bp通过lru分配一个block，并加上x-latch，用于保护block->frame
--buf_page_io_complete//释放x-latch。其它线程读取该page时候，需要等待buf_page_io_complete返回。
--fil_i
----同步模式：操作完成后直接调用buf_page_io_complete，释放x-latch
----异步模式：通过io-thread释放x-latch
------fil_aio_wait
----事务系统页，和insert buffer同步读。


多个线程并发处理同一个page时候，buf_page_init_for_read中通过buf_pool->mutex互斥。


## 6.随机预读

buf_read_page
--buf_read_ahead_random
随机预读是判断某个区域内的页是否大多数已经被访问，并且这些被访问的页是否为热点数据。
若满足条件，则innodb认为该区域内的页都可能被读到，提前进行读取操作。
将之后可能被访问的页通过顺序的方式读取，从而提高数据库的性能。

32个页中的9个被读过，满足条件。BUF_READ_AHEAD_RANDOM_AREA.

## 7.线性预读

判断页的访问是否是顺序的 
例如有一个自增主键id组成的表，进行表扫描操作就是线性预读。
算法：
读取一个页，若这个页是某个区域的边界(border)，并且该区域内的部分页都已经被顺序地访问（正向或者逆向）。则触发线性预读操作。顺序的读取之后或者之前的32个页。

区域：BUF_READ_AHEAD_LINEAR_AREA

若访问的页是边界且第一次被访问，并且该32个页中的12个页都已经被顺序的访问，则触发线性预读。
最后，线性预读要求物理上也是连续的页。

## 8.逻辑读取


buf_page_get_gen
--buf_page_hash_get。

若页不在bp中，首先通过物理读取从磁盘读入，若页已经在bp，则根据bp的哈希表来搜索

## 9.checkpoint

-sharp
----sharp:shutdown所有page写回磁盘。
-fuzzy
----master thread checkpoint
------每秒，每10秒。
----Async/Sync checkpoint
-------redo日志GAPß驱动
----FLUSH_LRU_LIST checkpoint
------Innodb需要保证 LRU链表和FREE LIST中随时有BUF_FLUSH_FREE_BLOCK_MARGIN + BUF_FLUSH_EXTRA_MARGIN（146个page）
------page被读取后，回到用buf_flush_free_margin，如果free list没有足够的page，需要flush。

## 10.double write


buf_flush_post_to_doublewrite_buf：用于在页写入前，将其复制到double write buffer，当收集满128个page，前置刷新到系统表空间doublewrite 段中。
然后再将bp中的page（异步）刷回磁盘。buf_flush_buffered_writes完成。


## 11.flush page

两种flush
--BUF_FLUSH_LRU
--BUF_FLUSH_LIST

buf_flush_write_block_low//刷新脏页要求redo log落盘。

innodb要求flush thread在flush之前不允许有任何page的latch，flush过程中需要持有page的s-latch，flush完成后io-thread释放s-latch.
在发起LRU_FLUSH的线程中，用户线程可能已经持有x-latch，flush的时候再加上s-latch，会造成死锁。因此，需要判断在LRU-flush时候，任何线程不能占有latch。